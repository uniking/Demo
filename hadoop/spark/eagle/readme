---------------------------------
测试资源
/home/sxis/study-linux-Demo/hadoop/spark/eagle/eagle-security-userprofile/training/src/main/resources/

----------------------------------
eagle 核密度估计代码

/home/sxis/workspace/incubator-eagle/eagle-security/eagle-security-userprofile/


kde模型实现
在文件中实现，
/home/sxis/study-linux-Demo/hadoop/spark/eagle/eagle-security-userprofile/training/src/main/java/org/apache/eagle/security/userprofile/model/kde/UserProfileKDEModeler.java
kde算法实现函数为UserProfileKDEModeler::computeProbabilityDensityEstimation

模型导出函数为UserProfileKDEModeler::generate

具体是序列化
在文件中
/home/sxis/study-linux-Demo/hadoop/spark/eagle/eagle-security-userprofile/common/src/main/scala/org/apache/eagle/security/userprofile/model/UserProfileModel.scala

/home/sxis/study-linux-Demo/hadoop/spark/eagle/eagle-security-userprofile/common/src/main/scala/org/apache/eagle/security/userprofile/model/UserProfileKDEModel.scala

序列化这个类，形成了
case class UserProfileKDEModel (
   override val version:Long,
   override val site:String,
   override val user:String,
   statistics: Array[UserCommandStatistics],
   minProbabilityEstimate:Double,
   maxProbabilityEstimate: Double,
   nintyFivePercentileEstimate: Double,
   medianProbabilityEstimate: Double
)

那模型就i是
   version
   site
   user
   statistics
   minProbabilityEstimate
   maxProbabilityEstimate
   nintyFivePercentileEstimate
   medianProbabilityEstimate
   
   
---------------------------------------
kde计算过程
（基于概率的，现有数据的每一条都有一个概率值，取最大和最小的进行判断）

打开chorme次数： 点击最小化次数： 打开淘宝次数： 移动窗口次数

12 845 67 98
11 800 60 90
10 820 63 95
12 833 66 95
13 800 66 99

以上为假设矩阵，一行为一组用户的行为，一列为同一事件的行为，整个矩阵就是用户的行为描述。
1，计算statistics
计算均值和方差，以一列计算呢还是以一行计算呢？很显然以一列计算才有意义，比如打开淘宝次数的均值和方差。
计算的个数同行为的种类，也就是列的数目。
        for(int i=0; i<m.getColumnDimension(); i++){
            UserCommandStatistics stats = new UserCommandStatistics();
            stats.setCommandName(this.cmdTypes[i]);
            RealVector colData = m.getColumnVector(i);
            StandardDeviation deviation = new StandardDeviation();
            double stddev = deviation.evaluate(colData.toArray()); //计算 标准差

            if(LOG.isDebugEnabled()) LOG.debug("Stddev is NAN ? " + (Double.isNaN(stddev) ? "yes" : "no"));
            if(stddev <= lowVarianceVal)
                stats.setLowVariant(true);
            else
                stats.setLowVariant(false);

            stats.setStddev(stddev);
            Mean mean = new Mean(); //计算 均值
            double mu = mean.evaluate(colData.toArray());
            if(LOG.isDebugEnabled()) LOG.debug("mu is NAN ? " + (Double.isNaN(mu)? "yes":"no"));

            stats.setMean(mu);
            statistics[i]=stats;
        }

2，计算概率估计
现在就是以一组行为为对象，计算第i组发生的概率

	       |概率密度
12 845 67 98 ---      12*845*67*98
11 800 60 90 -----    11*800*60*90
10 820 63 95 ------
12 833 66 95 ---
13 800 66 99 ----

        for(int i=0; i < inputMat.getRowDimension(); i++){
            for(int j=0; j < inputMat.getColumnDimension(); j++){
                if(statistics[j].getStddev() > 0){
                    double stddev = statistics[j].getStddev();
                    double mean = statistics[j].getMean();
                    double sqrt2PI = Math.sqrt(2.0*Math.PI);
                    double denominatorFirstPart = sqrt2PI*stddev;
                    double squareMeanNormal = Math.pow((inputMat.getEntry(i, j) - mean), 2);
                    double twoPowStandardDev = Math.pow(stddev, 2);
                    double twoTimesTwoPowStandardDev = 2.0*twoPowStandardDev;
                    probabilityEstimation[i] *= ((1.00/denominatorFirstPart)
                            *(Math.exp(-(squareMeanNormal/twoTimesTwoPowStandardDev))));
                }
            }
        }
        
probabilityEstimation[i] *= ((1.00/((Math.sqrt(2.0*Math.PI))*stddev)) * (Math.exp(-( (Math.pow((inputMat.getEntry(i, j) - mean), 2)) / (2.0*(Math.pow(stddev, 2)))))));
那可以总结下这个用户画像模型：1，作某件事的均值和方差 2，某组事件发生的概率

-------------------------
使用用户画像模型
UserActivityAggregator.java 用户行为聚合
UserProfileAnomalyDetector.java 匿名行为检测

可使用在
UserProfileDetectionBatchMain.java 批处理中（非时时 storm）
UserProfileDetectionStreamMain.java 流中（时时 storm）

实现文件
/home/sxis/study-linux-Demo/hadoop/spark/eagle/eagle-security-userprofile/detection/src/main/java/org/apache/eagle/security/userprofile/impl/UserProfileAnomalyKDEEvaluator.java

要做的事情：
1，收集用户行为，为一组动作。（一组动作-》一个行为）
收集n组动作
比如
10 805 60 93
13 825 62 93
10 855 68 90
如果不是行为组，没法计算行为的概率密度。

2，对挨个对动作进行均值，方差判断
上面进行3*4=12此判断，标记是不是正常的动作。

3，判断是不是匿名
判断概率密度

for(int i=0; i<inputData.getRowDimension();i++){
            List<String> cmds = JavaConversions.seqAsJavaList(userActivity.cmdTypes());
            if(inputData.getColumnDimension() != cmds.size()){
                LOG.error("Test data is not with same dimension as training, aborting...");
                return null;
            }else{

                UserCommandStatistics[] listStats = aModel.statistics();

                for(int j=0; j < inputData.getColumnDimension(); j++){
//                    LOG.info("mean for j=" + j + " is:" + listStats[j].getMean());
//                    LOG.info("stddev for j=" + j + " is:" + listStats[j].getStddev());
                    if(listStats[j].isLowVariant()){
//                        LOG.info(listStats[j].getCommandName() + " is low variant for user: " + user);
                        if(inputData.getEntry(i, j) > listStats[j].getMean()){
                            probabilityEstimation[i]*= Double.NEGATIVE_INFINITY;
                            anomalyFeature[i][j] = true;
                        }
                    }else{
                        double stddev = listStats[j].getStddev();
                        //LOG.info("stddev: " + stddev);
                        double mean = listStats[j].getMean();
                        //LOG.info("mean: " + mean);
                        double sqrt2PI = Math.sqrt(2.0*Math.PI);
                        //LOG.info("sqrt2PI: " + sqrt2PI);
                        double denominatorFirstPart = sqrt2PI*stddev;
                        //LOG.info("denominatorFirstPart: " + denominatorFirstPart);
                        double squareMeanNormal = Math.pow((inputData.getEntry(i, j) - mean), 2);
                        //LOG.info("squareMeanNormal: " + squareMeanNormal);
                        double twoPowStandardDev = Math.pow(stddev, 2);
                        //LOG.info("twoPowStandardDev: " + twoPowStandardDev);
                        double twoTimesTwoPowStandardDev = 2.0*twoPowStandardDev;
                        //LOG.info("twoTimesTwoPowStandardDev: " + twoTimesTwoPowStandardDev);

                        double tempVal = ((1.00/denominatorFirstPart)
                                *(Math.exp(-(squareMeanNormal/twoTimesTwoPowStandardDev))));
                        probabilityEstimation[i] *= tempVal;
                        //LOG.info("probabilityEstimation: " + probabilityEstimation[i]);
                        if((inputData.getEntry(i, j) - mean) > 2*stddev)
                            anomalyFeature[i][j] = true;
                    }
                }

                for(int i=0; i < probabilityEstimation.length;i++){
            MLCallbackResult callBackResult = new MLCallbackResult();
            callBackResult.setContext(context);
            //LOG.info("probability estimation for data @" + i + " is: " + probabilityEstimation[i]);
            if(probabilityEstimation[i] < aModel.maxProbabilityEstimate()){
                callBackResult.setAnomaly(true);
                for(int col = 0 ; col < anomalyFeature[i].length; col++){
                    //LOG.info("feature anomaly? " + (featureVals[col] == true));
                    if(anomalyFeature[i][col] == true){
                        callBackResult.setFeature(aModel.statistics()[col].getCommandName());
                    }
                }
            }else{
                callBackResult.setAnomaly(false);
            }
